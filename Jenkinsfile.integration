#!groovy


def compute_node='storage-compute'
def testbed_node="${currentBuild.fullProjectName.replace('/', '_')}-${currentBuild.number}"

def compute_workspace="/tmp/ws/${currentBuild.fullProjectName}/${currentBuild.number}"
def jcs_repo="${compute_workspace}/jcs"
def jcs_venv="${compute_workspace}/jcs/venv"

// images
def testbed_image = [
    'openSUSE-Leap-15.2': 'minimal-opensuse-15.2-x86_64',
    'openSUSE-Leap-15.3': 'minimal-opensuse-15.3-x86_64',
    'openSUSE-Leap-15.4': 'minimal-opensuse-15.4-x86_64'
]

// repositories
def repos = [
    'openSUSE-Leap-15.2': [
        'http://download.opensuse.org/distribution/leap/15.2/repo/oss/',
        'http://download.opensuse.org/update/leap/15.2/oss/',
        'https://download.opensuse.org/repositories/Virtualization:/vagrant/openSUSE_Leap_15.2'
    ],
    'openSUSE-Leap-15.3': [
        'http://download.opensuse.org/distribution/leap/15.3/repo/oss/',
        'http://download.opensuse.org/update/leap/15.3/oss/',
    ],
    'openSUSE-Leap-15.4': [
        'http://download.opensuse.org/distribution/leap/15.4/repo/oss/',
        'http://download.opensuse.org/update/leap/15.4/oss/',
    ]
]

def sesdev_deps = [
    'gcc',
    'git-core',
    'libvirt',
    'libvirt-devel',
    'patterns-server-kvm_server',
    'patterns-server-kvm_tools',
    'python3-devel',
    'python3-virtualenv',
    'vagrant',
    'vagrant-libvirt',
]

// packages creating conflicts. These will be removed from the agent.
def conflict_deps = [
  'openSUSE-Leap-15.2': [],
  'openSUSE-Leap-15.3': [],
  'openSUSE-Leap-15.4': [],
]

// parameters depending on the selected cloud
def cloud_params = [
    'ovh': [
        'cloud_network_public': 'Ext-Net',
        'cloud_security_group': 'default',
        // https://www.ovhcloud.com/en/public-cloud/prices/ for ovh instance types
        'cloud_instance_type': 's1-8'
    ],
    'ecp': [
        'cloud_network_public': 'floating',
        'cloud_security_group': 'sesci',
        'cloud_instance_type': 'm1.medium'
    ]
]

def sesdev_create_cmd(ceph_salt_git_repo, ceph_salt_git_branch, extra_repo_urls) {
    cmd = "sesdev create pacific --salt --non-interactive"
    if (!ceph_salt_git_repo.isEmpty()) {
        if (ceph_salt_git_branch.isEmpty()) {
            error('ceph-salt git repo set, but no ceph-salt git branch given')
        }
        cmd += " --ceph-salt-repo ${ceph_salt_git_repo} --ceph-salt-branch ${ceph_salt_git_branch}"
    }

    if (!extra_repo_urls.isEmpty()) {
        cmd += extra_repo_urls.split(/\s+/).collect() {
            " --repo $it"
        }.join('')
    }

    cmd += " --single-node mini"
    return cmd
}

pipeline {
    agent none

    options {
        skipDefaultCheckout()
        parallelsAlwaysFailFast()
    }

    parameters {
        /* first value in the list is the default */
        choice(name: 'OS_CLOUD', choices: ['ovh', 'ecp'], description: 'OpenStack Cloud to use')
        choice(name: 'OS', choices: [
                                'openSUSE-Leap-15.4',
                                'openSUSE-Leap-15.3',
                                'openSUSE-Leap-15.2',
                            ],
               description: 'Operating system to use')
        string(name: 'CEPH_SALT_GIT_REPO', defaultValue: 'https://github.com/ceph/ceph-salt.git',
               description: 'ceph-salt git repository to use for installation. If empty, the RPM package is used')
        string(name: 'CEPH_SALT_GIT_BRANCH', defaultValue: 'master',
               description: 'ceph-salt git branch to use for installation. This parameter is only used when CEPH_SALT_GIT_REPO is set')
        string(name: 'EXTRA_REPO_URLS', defaultValue: '',
               description: 'Extra zypper repo url(s) that will be added to all nodes. Multiple repos must be separated by space')
        string(name: 'SLEEP_WHEN_FAILING', defaultValue: '1',
               description: 'Keep the environment available for X minutes when job failed')
        string(name: 'CUSTOM_JOB_NAME', defaultValue: '',
               description: 'If set, a custom job name will be set')
        string(name: 'CUSTOM_JOB_DESC', defaultValue: '',
               description: 'If set, a custom job description will be set')
        string(name: 'CUSTOM_JCS_REPO',
               defaultValue: 'https://github.com/kshtsk/jcs.git@fix-jenkins-version-check',
               description: 'Use customized version of jcs to deploy worker')
    }

    environment {
        OS_CLOUD = "${params.OS_CLOUD}"
        VAGRANT_DEFAULT_PROVIDER = 'libvirt'
        JENKINS_URL = 'http://see.prv.suse.net:8080'
        JENKINS_USERNAME = 'storage'
        JENKINS_PASSWORD = credentials('storage-ci-suse-de-jenkins-password')
    }
    stages {
        stage('Create jenkins agent') {
            agent {
                label "${compute_node}"
            }
            steps {
                script {
                    if (!params.CUSTOM_JOB_NAME.isEmpty()) {
                        currentBuild.displayName = "${params.CUSTOM_JOB_NAME}"
                    }
                    if (!params.CUSTOM_JOB_DESC.isEmpty()) {
                        currentBuild.description = "${params.CUSTOM_JOB_DESC}"
                    }
                }
                sh """
                    mkdir -p ${compute_workspace}
                    virtualenv ${jcs_venv}
                    source ${jcs_venv}/bin/activate
                    python3 -m pip install --upgrade pip
                    pip3 --use-feature=2020-resolver install \
                        git+${params.CUSTOM_JCS_REPO}#egg=jcs[openstack,obs,jenkins]
                    jcs \
                        --os-network-public ${cloud_params[params.OS_CLOUD]['cloud_network_public']} \
                        create \
                        --cloud openstack \
                        --instance-type ${cloud_params[params.OS_CLOUD]['cloud_instance_type']} \
                        --jenkins-credential storage-automation-for-root-user \
                        ${testbed_image[params.OS]} ${testbed_node}"""
            }
        }

        stage('zypper remove conflicts') {
            agent { label "${testbed_node}" }
            when {
                expression { return conflict_deps.get(params.OS, []) != [] }
            }
            steps {
                sh 'zypper -n remove ' + conflict_deps[params.OS].join(' ')
            }
        }

        stage('zypper add repos and refresh') {
            agent { label "${testbed_node}" }
            steps {
                sh ((repos[params.OS].indexed().collect { i, url ->
                    "zypper -n ar --no-gpgcheck $url $i"
                } + [
                    'zypper -n refresh',
                    'zypper -n repos -d',
                ]).join("\n"))
            }
        }

        stage('Install sesdev dependencies') {
            agent { label "${testbed_node}" }
            steps {
                sh 'zypper -n install ' + sesdev_deps.join(' ')
            }
        }

        stage('Setup libvirt') {
            agent { label "${testbed_node}" }
            steps {
                sh '''
                    usermod -a -G libvirt $(whoami)
                    systemctl enable libvirtd
                    systemctl restart libvirtd
                    mkdir /libvirt-pool
                    virsh pool-define-as --name default --type dir --target /libvirt-pool
                    virsh pool-start default
                    virsh net-start default
                    virsh net-list --all
                    virsh pool-list --all'''
            }
        }

        stage('Install sesdev from source and create cluster') {
            agent { label "${testbed_node}" }
            steps {
                checkout scm
                timeout(time: 90, unit: 'MINUTES') {
                    ansiColor('xterm') {
                        sh """
                            ./bootstrap.sh
                            source venv/bin/activate
                            sesdev --help
                            ${sesdev_create_cmd(params.CEPH_SALT_GIT_REPO,
                                                params.CEPH_SALT_GIT_BRANCH,
                                                params.EXTRA_REPO_URLS)}"""
                    }
                }
            }
        }

        stage('Run QA tests on the cluster') {
            agent { label "${testbed_node}" }
            steps {
                timeout(time: 90, unit: 'MINUTES') {
                    sh """
                        source venv/bin/activate
                        sesdev --version
                        sesdev status
                        sesdev qa-test mini
                    """
                }
            }
        }
    }

    post {
        // cleanup is executed after every other post step
        failure {
            node("${compute_node}") {
                sh "sleep ${params.SLEEP_WHEN_FAILING.toInteger() * 60}"
            }
        }
        cleanup {
            node("${testbed_node}") {
                sh """
                    source venv/bin/activate
                    mkdir artifacts
                    sesdev scp -r mini master:/var/log/ceph artifacts/ || true
                    sesdev scp -r mini master:/var/log/salt artifacts/ || true
                    sesdev scp mini master:/var/log/ceph-salt.log artifacts/ || true
                    sesdev ssh mini master -- ps auxww --forest > artifacts/ps || true
                    sesdev ssh mini master journalctl > artifacts/journalctl || true

                """
                archiveArtifacts artifacts: 'artifacts/**/*', allowEmptyArchive: true
            }
            node("${compute_node}") {
                retry(10) {
                    sh """
                        source ${jcs_venv}/bin/activate
                        jcs delete --cloud openstack ${testbed_node}"""
                    sleep 10
                }
                sh "rm -rf ${compute_workspace}"
            }
        }
    }
}
